## Kubernetes



### Kubernetes?

대규모 서비스에 사용될 수 있는 컨테이너 오케스트레이션 솔루션으로 크게 컨테이너화 된 애플리케이션을 관리, 자동 배포, 스케일링 등 기능을 제공하며 대규모 확장성, 무한한 유연성, 어느곳에서나 실행이 가능한 장점을 가지고 있다.





### Kubernetes의 등장배경

가상화 배포 이전에는 한대의 물리서버에서 여러 애플리케이션을 동작했고, 프로세스 별로 리소스 사용에 대한 제약을 정하기 어려웠다. 이를 극복하기 위하여 가상화 기반 배포방식이 개발되었지만, 각 애플리케이션마다 가상머신을 따로 설치했고 이에 따른 오버헤드 문제가 제기되었다.

도커라는 컨테이너 기반 배포 방식이 새로 등장하였고, 도커 엔진을 통한 컨테이너 런타임 공유로 인하여 가상화 기반보다 가벼우면서 독립적인 파일 시스템, 리소스 활용 등 다양한 인프라에서 사용될 수 있도록 컨테이너 배포 방식이 개발되었다.





### Kubernetes구조

![구조](.\구조.png)

크게 마스터노드, 워커노드 두 부분으로 기능적 역할이 구분된다.



**마스터노드**

> etcd : 클러스터와 관련된 상태 값을 포함한 데이터를 저장하는 저장공간. 키-값 형태로 데이터를 분산저장하며 여러 곳에 복제하여 재해 발생시 쉽게 복구할 수 있다.

>  api 서버 : 마스터 노드와 워커 노드간 통신을 담당하며 etcd에 저장된 상태와 일치하는지 점검하고 요구된 상태가 될 수 있도록 관리. 외부에서 kubectl을 사용하여 제어

> 컨트롤러 매니저 : 클러스터에 명시된 상태가 되도록 api서버와 통신하는 역할이며 크게 노드 컨트롤러, 레플리케이션 컨트롤러, 엔드포인트 컨트롤러, 토큰 컨트롤러 등이 있다.

> 스케쥴러 : 파드가 생성될 때 파드를 실행할 클러스터의 노드를 선택하는 역할.



**워커노드**

> kubelet : 워커 노드에서 실행되는 에이전트로 파드에 따라 컨테이너가 정상적으로 실행되고 있는지 관리.

> kube-proxy : 워커 노드에서 실행되는 네트워크 및 로드 밸런싱 프록시로 파드내에 실행중인 컨테이너를 외부로 노출시켜 외부에서 컨테이너에 접근할 수 있도록 한다. 또한 특정 포트와 IP 주소로 외부의 요청이 올때 해당 요청에 대응하는 컨테이너로 네트워크 트래픽을 전달하는 역할을 한다.

![파드](.\파드.png)

> **파드** : 한개 이상의 컨테이너로 구성된 컨테이너 그룹으로 스케쥴링의 기본 단위. 파드 내의 컨테이너는 동일한 노드에 위치하며 같은 노드에 배치된 파드는 동일한 IP 주소로 할당되지만 다른 포트 번호를 부여한다. 동일한 파드 내의 컨테이너들은 상호 참조가 가능하고 스토리지 및 네트워크를 공유하지만 다른 파드에 있는 컨테이너와는 IP주소로 통신한다.





### 파드의 생명주기

![lifecycle](.\lifecycle.webp)

1. kubectl을 통하여 api서버에 파드생성 요청
2. API서버에 전달된 내용이 있다면 API서버는 ectd에 전달된 내용을 모두 기록해 클러스터를 최신화.
3. API서버에 파드 생성이 요청된 것을 컨트롤러 매니저가 인지하면 컨트롤러 매니저는 파드를 생성하고 API 서버에 상태값을 리턴(아직 어떤 노드에 생성할지는 결정하지 않음)
4. 파드가 생성된 것을 스케줄러가 인지 -> 생성된 파드를 어떤 워커 노드에 적용할지 조건을 고려하여 결정하고 노드에 파드를 생성
5. API 서버에 전달된 정보대로 워커노드에 파드가 속해 있는지 스케줄러가 kubelet으로 확인
6. kubelet 에서 컨테이너 런타임으로 파드 생성 요청





**API-server는 write하고 watch 만 한다** -> 선언적인 시스템 구조로 현재 상태와 맞는지 점검하고 그 것에 맞추려고 노력한다.(하향식) 따라서 etcd의 값과 API서버의 상태가 중요하며 나머지는 그에 맞춰 조정된다.

![api](.\api.webp)

**(api 서버는 값을 리턴받지 않는다...!)**











## kubeflow



### Kubeflow 란?

ML을 개발하고 배포하기 위한 오픈소스 플랫폼으로 개발, 테스트 및 배포와 운영까지 가능하며 웹으로 구현되어있어 사용하기 간편한 장점이 있다.

![kubeflow-overview-platform-diagram](.\kubeflow-overview-platform-diagram.svg)





### 왜 사용해야하나?

기존 jupyter 노트북은 개인의 로컬에서 진행되는 테스트로 한정되어있지만, kubeflow를 활용하여 여러 사람이 공유되어 연구할 수 있으며 각 로컬 서버에 데이터를 복사하는 대신 사용할 수 있다.

다양한 라이브러리를 지원하며 오픈소스 기반 프로젝트에 의존하기 때문에 확장성이 매우 높다.





### Pipeline

컨테이너 기반의 end-to-end ML 워크 플로우를 만들고 배포할 수 있는 쿠버네티스 플랫폼으로 컨테이너 기반으로 구성되어 있어 확장 및 재사용성이 용이하다.

파이프라인은 워크플로우의 컴포넌트들과 컴포넌트를 그래프 형태로 결합하는 것 그리고 입/출력에 대한 정의 역시 포함한다.

여러 대의 서버와 여려 개의 서비스를 편리하게 관리해주는 작업(현세님이 찾는 것과 비슷.)

스케쥴링, 클러스터링, 서비스 디스커버리, 로깅, 모니터링 등 일을 수행



![파이프라인](.\파이프라인.png) 

1. python SDK를 사용하여 컴포넌트를 작성 하면  DSL complier가 읽고 yaml 파일로 변환한다. 
2. 파이프라인을 생성하기 위하여 pipeline service 호출
3. pipeline service는 쿠버네티스 API 서버 호출
4. 쿠버네티스 리소스에 정의된 파이프라인을 실행하기 위하여 컨테이너 실행 -> 파드 수행



 

### Fairing

손쉽게 ML모델을 학습/배포할 수 있는 파이썬 패키지로 jupyter 노트북에서 쿠버네티스 클러스터로 ML모델의 생성, 학습, 배포를 요청

jupyter 노트북, 파이썬 파일을 도커이미지를 빌드 후 이미지 레지스트리에 푸쉬하며 이를 쿠버네티스 리소스로 변환하여 API서버로 요청

![fairing](.\fairing.png)





### 왜 사용해야할까?

손쉬운 ML train job 패키징 : ML 모델 학습 코드와 해당 코드의 환경을 Docker 이미지로 쉽게 패키징

하이브리드 클라우드 환경에서 쉬운 모델 학습 : 인프라를 추상화 키셔 ML모델을 train하기 위한 API 제공

학습 모델에 대한 serving 및 deployment 간소화 : 클라우드 환경에서 쉽게 서빙하고 배포할 수 있다.

